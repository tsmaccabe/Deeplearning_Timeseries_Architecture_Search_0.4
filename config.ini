# Architecture Settings
#   Legend
#       Architecture Type | (:fixed, <length>, <width>),
#                           (:encoder, <length>),
#                           (:decoder, <length>)
#       Activations       | :leakyrelu, :relu, :sigmoid, :tanh
architecture_type = (:fixed, [5, 10, 15], [5, 10, 15])
activation = [:relu]

# Search Settings
#   Legend
#       Stop Conditions   | (:max_epochs, <max_epochs>),
#                           (:epochs_stagnant, <epochs_stagnant>)
#       Cooling Schedule  | (:exp, <init_temp>, <final_temp>, <final_temp_epoch>),
#                           (:linear, <init_temp>, <final_temp>, <final_temp_epoch>)
#       Shift Settings    | (:exp, <radial_scale>),
#                           (:uniform, <radial_scale>)
#       Trials Per State  | <trials_per_state>
stop_condition_search = (:epochs_max, 100)
cool_schedule = (:exp, 0.5, 0.05, 100)
shift_settings = (:exp, 10.0)
trials_per_state = 100

# Training Settings
#   Legend
#       Stop Conditions   | (:max_epochs, <max_epochs>),
#                           (:epochs_stagnant, <epochs_stagnant>)
#       Learning Rate     | (:constant, <learn_rate>),
#                           (:exp, <init_rate>, <final_rate>, <final_rate_epoch>),
#                           (:linear, <init_rate>, <final_rate>, <final_rate_epoch>)
#       Loss Functions    | :mae, :mse, :cross_entropy
#       Dropout           | <dropout_rate>
#       Regularization    | :none,
#                           (:l1, <reg_scale>),
#                           (:l2, <reg_scale>)
stop_condition_train = (:epochs_max, 100)
loss_function = :mae
learn_rate = (:exp, 100, 0.01, 0.002)
dropout_rate = 0.2
regularization = (:l2, 0.1)